{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dbGaP spreadsheet - CalTech\n",
    "## Create folder and copy definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shutil import copytree\n",
    "from shutil import rmtree\n",
    "import pathlib\n",
    "import json\n",
    "import yaml\n",
    "import hubmapbags\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from warnings import warn as warning\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "instance = 'prod'\n",
    "token = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found on disk. Loading uuid-protected-data-report/20230120.pkl.\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "output_directory = 'data'\n",
    "if not Path(output_directory).exists():\n",
    "    Path(output_directory).mkdir()\n",
    "\n",
    "report_output_directory = 'uuid-protected-data-report'\n",
    "if not Path(report_output_directory).exists():\n",
    "    Path(report_output_directory).mkdir()\n",
    "\n",
    "report_output_filename = report_output_directory + '/' + str(now.strftime('%Y%m%d')) + '.pkl'\n",
    "print('File found on disk. Loading ' + report_output_filename + '.')\n",
    "report = pd.read_pickle(report_output_filename.replace('tsv', 'pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbgap_study_id( datum ):\n",
    "        if ( datum['group_name'] == 'University of California San Diego TMC' ) or \\\n",
    "                ( datum['group_name'] == 'Broad Institute RTI' and datum['data_type'] == 'Slide-seq' ):\n",
    "                return 'phs002249'\n",
    "        elif datum['group_name'] == 'Stanford TMC':\n",
    "                return 'phs002272'\n",
    "        else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Stanford TMC', 'University of California San Diego TMC',\n",
       "       'Broad Institute RTI', 'University of Florida TMC',\n",
       "       'EXT - Human Cell Atlas', 'TMC - University of Connecticut',\n",
       "       'California Institute of Technology TMC'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report['group_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = report[report['group_name'] == 'California Institute of Technology TMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:11,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if not Path('caltech-dataframe.tsv').exists():\n",
    "    columns = ['phs_accession','sample_ID','library_ID', \\\n",
    "               'title','group_name','data_type','library_strategy', \\\n",
    "               'library_source','library_selection', \\\n",
    "               'library_layout','platform','instrument_model', \\\n",
    "               'design_description','reference_genome_assembly', \\\n",
    "               'alignment_software']\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    phs_accession = '<foobar>'\n",
    "    \n",
    "    rows = []\n",
    "    lib_counter = 1\n",
    "    for index, datum in tqdm(report.iterrows()):\n",
    "        metadata = hubmapbags.apis.get_dataset_info(datum['hubmap_id'], instance='prod', token=token)\n",
    "        pmetadata = hubmapbags.apis.get_provenance_info(datum['hubmap_id'], instance='prod', token=token)\n",
    "\n",
    "        organ = pmetadata['organ_type'][0]\n",
    "\n",
    "        library_ID = metadata['ingest_metadata']['metadata']['library_id']\n",
    "        library_ID = library_ID + '-' + datum['hubmap_id']\n",
    "\n",
    "        instrument_model = metadata['ingest_metadata']['metadata']['acquisition_instrument_model']\n",
    "\n",
    "        platform = metadata['ingest_metadata']['metadata']['acquisition_instrument_vendor']\n",
    "\n",
    "        if metadata['ingest_metadata']['metadata']['library_layout'] == 'paired-end':\n",
    "            library_layout = 'paired'\n",
    "        else:\n",
    "            library_layout = 'single'\n",
    "\n",
    "        library_selection = 'other'\n",
    "\n",
    "        if metadata['ingest_metadata']['metadata']['analyte_class'] == 'DNA':\n",
    "            library_strategy = 'ATAC-seq'\n",
    "            title= datum['data_type'] + ' of human ' + organ\n",
    "            library_source = 'GENOMIC'\n",
    "        else:\n",
    "            library_strategy = 'RNA-Seq'\n",
    "            title= datum['data_type'] + ' of human ' + organ\n",
    "            library_source = 'TRANSCRIPTOMIC'\n",
    "\n",
    "        library_construction_protocols_io_doi = metadata['ingest_metadata']['metadata']['library_construction_protocols_io_doi']\n",
    "        sequencing_reagent_kit = metadata['ingest_metadata']['metadata']['sequencing_reagent_kit']\n",
    "        design_description = f'<TEMP>SNARE-seq2 was performed as outlined (Nature Protocols, DOI:10.1038/s41596-021-00507-3) and according to the following protocols.io protocol: dx.doi.org/{library_construction_protocols_io_doi}. The library was sequenced on the {platform} {instrument_model} system using the {sequencing_reagent_kit} kit.'\n",
    "\n",
    "        row = {'phs_accession':phs_accession, \\\n",
    "               'sample_ID':datum['hubmap_id'], \\\n",
    "               'library_ID':library_ID, \\\n",
    "               'title':title, \\\n",
    "               'group_name':datum['group_name'], \\\n",
    "               'data_type':datum['data_type'], \\\n",
    "               'library_strategy':library_strategy , \\\n",
    "               'library_source':library_source , \\\n",
    "               'library_selection':library_selection, \\\n",
    "               'library_layout':library_layout, \\\n",
    "               'platform':platform, \\\n",
    "               'instrument_model':instrument_model, \\\n",
    "               'design_description':design_description, \\\n",
    "               'reference_genome_assembly':None, \\\n",
    "               'alignment_software':None }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    for row in rows:\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "    df.to_csv( 'caltech-dataframe.tsv', sep='\\t', index=False )\n",
    "else:\n",
    "    df = pd.read_csv( 'caltech-dataframe.tsv', sep='\\t' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('caltech.pkl').exists():\n",
    "    file = open('caltech.pkl', 'rb')\n",
    "    files = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    df[\"filetype0\"]=None\n",
    "    df[\"filename0\"]=None\n",
    "    df[\"checksum0\"]=None\n",
    "    df[\"filetype1\"]=None\n",
    "    df[\"filename1\"]=None\n",
    "    df[\"checksum1\"]=None\n",
    "    df[\"filetype2\"]=None\n",
    "    df[\"filename2\"]=None\n",
    "    df[\"checksum2\"]=None\n",
    "    df[\"filetype3\"]=None\n",
    "    df[\"filename3\"]=None\n",
    "    df[\"checksum3\"]=None\n",
    "    df[\"filetype4\"]=None\n",
    "    df[\"filename4\"]=None\n",
    "    df[\"checksum4\"]=None\n",
    "    df[\"filetype5\"]=None\n",
    "    df[\"filename5\"]=None\n",
    "    df[\"checksum5\"]=None\n",
    "    df[\"filetype6\"]=None\n",
    "    df[\"filename6\"]=None\n",
    "    df[\"checksum6\"]=None\n",
    "    df[\"filetype7\"]=None\n",
    "    df[\"filename7\"]=None\n",
    "    df[\"checksum7\"]=None\n",
    "\n",
    "    for index, datum in df.iterrows():\n",
    "        if len(files[index]) == 1:\n",
    "            keys = list(files[index].keys())\n",
    "            df.loc[index,'checksum0'] = files[index][keys[0]]\n",
    "            df.loc[index,'filename0'] = keys[0]\n",
    "            df.loc[index,'filetype0'] = 'fastq'\n",
    "        elif len(files[index]) == 2:\n",
    "            keys = list(files[index].keys())\n",
    "            df.loc[index,'checksum0'] = files[index][keys[0]]\n",
    "            df.loc[index,'filename0'] = keys[0]\n",
    "            df.loc[index,'checksum1'] = files[index][keys[1]]\n",
    "            df.loc[index,'filename1'] = keys[1]\n",
    "            df.loc[index,'filetype0'] = df.loc[index,'filetype1'] = 'fastq'\n",
    "        else:\n",
    "            keys = list(files[index].keys())\n",
    "            df.loc[index,'checksum0'] = files[index][keys[0]]\n",
    "            df.loc[index,'filename0'] = keys[0]\n",
    "            df.loc[index,'checksum1'] = files[index][keys[1]]\n",
    "            df.loc[index,'filename1'] = keys[1]\n",
    "            df.loc[index,'checksum2'] = files[index][keys[2]]\n",
    "            df.loc[index,'filename2'] = keys[2]\n",
    "            df.loc[index,'checksum3'] = files[index][keys[3]]\n",
    "            df.loc[index,'filename3'] = keys[3]\n",
    "            df.loc[index,'checksum4'] = files[index][keys[4]]\n",
    "            df.loc[index,'filename4'] = keys[4]\n",
    "            df.loc[index,'checksum5'] = files[index][keys[5]]\n",
    "            df.loc[index,'filename5'] = keys[5]\n",
    "            df.loc[index,'checksum6'] = files[index][keys[6]]\n",
    "            df.loc[index,'filename6'] = keys[6]\n",
    "            df.loc[index,'checksum7'] = files[index][keys[7]]\n",
    "            df.loc[index,'filename7'] = keys[7]\n",
    "            df.loc[index,'filetype0'] = df.loc[index,'filetype1'] = \\\n",
    "            df.loc[index,'filetype2'] = df.loc[index,'filetype3'] = \\\n",
    "            df.loc[index,'filetype4'] =  df.loc[index,'filetype5'] = \\\n",
    "            df.loc[index,'filetype6'] =  df.loc[index,'filetype7'] = 'fastq'\n",
    "\n",
    "    df.to_csv('caltech-spreadsheet.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
